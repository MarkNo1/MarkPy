{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Unconditional generation\n",
    "As a quick recap with unconditional generation, you get outputs from random classes. You can think of those as a gumball\n",
    "machine, where you input a coin and you get a random color gumball. If you want to gumball of a specific color, say red,\n",
    "you have to keep spinning coins until you get it. In this example, the coin is like the random noise vector that your GAN\n",
    "uses for generation and the gumball machine is like the generator. Then the gumballs are the random outputs, those images\n",
    "you get. You can see what color gumballs you might get, just like how you know what your GAN is trained on.\n",
    "You can't control what exact color of output you will get.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conditional generation\n",
    "On the other hand, conditional generation allows you to ask for an example from a specific class and you get what you ask for.\n",
    "It's like a vending machine. You input a coin similar to the gumball machine but you input a coin along with a code for an\n",
    "item that you want. For example, A2 for a red soda. But note that you still don't control certain features of the soda bottle.\n",
    "You can't get the one with the latest expiration date or the bottle that's least damaged or the one that's filled up the most,\n",
    "you just get a random red soda. But it is a red soda, not a blue candy bar. Here the coin and the code are the inputs for\n",
    "the GAN and the vending machine is the generator and the soda is the generated output. With a conditional GAN, you get a\n",
    "random example from the class you specify. That class is this A2 soda here.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conditional vs Unconditional generation\n",
    "\n",
    "<img src=\"images/condVSuncond.png\" width=420 height=200 />\n",
    "\n",
    "With conditional generation, you can get generated examples from the classes you decide while with unconditional generation,\n",
    "you get examples from a random class. As a result of that, with conditional generation, you actually have to train your\n",
    "GAN with labeled datasets and those labels are on the different classes you want while unconditional generation doesn't\n",
    "need any labels. You've seen this in previous weeks from the course, that you don't need any labels you just need a pile\n",
    "of real examples. You see how to modify your model for this conditional generation in the following lectures.\n",
    "What you should take away from this video is that conditional generation requires labeled datasets for training in\n",
    "order to learn how to produce examples from desired classes. Coming up, I'll show you how the labels from your dataset\n",
    "are fed to the generator and discriminator in order to train your GAN and produce examples from the desired class, like\n",
    "selecting the red soda from a vending machine.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conditional generation - INPUT\n",
    "You've seen already with unconditional generation, the generator needs a noise vector to produce random examples.\n",
    "For conditional generation, you also need a vector to tell the generator from which class the generated examples should come from.\n",
    "Usually this is a one-hot vector\n",
    "\n",
    "<img src=\"images/cond-input.png\" width=420 height=200 />\n",
    "\n",
    "There's one-hot vector is now what lets you control what class to generate. The input to the generator in a conditional\n",
    "GAN is actually a concatenated vector of both the noise and the one-hot class information.\n",
    "\n",
    "\n",
    "<img src=\"images/cond-input-1.png\" width=420 height=200 />"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So it's one huge vector. For example, with a class vector here representing a husky breed, the generator will ideally\n",
    "produce a husky dogs from one noise vector. But if you change that noise vector, it should produce a different husky dog;\n",
    "while the class information stays the same. Well, that's actually because the discriminator will also be given this class\n",
    "information. The generator, needs to fool the discriminator; so you'll see how this happens.\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discriminator - Input\n",
    "\n",
    "The discriminator in a similar way will take the examples, but now they're paired with the class information as input\n",
    "to determine if the examples are either real or fake representations of that particular class; and that's what's key here.\n",
    "For example, with this class of golden retriever, but in image of a beagle dogs.\n",
    "\n",
    "<img src=\"images/cond-input-2.png\" width=420 height=200 />\n",
    "\n",
    "So not a golden retriever being fed in. This discriminated arches actually say this is fake because that is not a real\n",
    "looking golden retriever, even though it's a very real looking image of a beagle.\n",
    "\n",
    "This is just 5 percent real is what it's going to say. As a result, for the discriminator to predict that an example is\n",
    "real, it needs to look like the examples from that class in the training data set. The training data-set is key here\n",
    "because it'll get these real labels next to it.\n",
    "\n",
    "\n",
    "Digging a little bit deeper, the input to the discriminator is an image. How do you go about adding that class information?\n",
    "Well, the image is fed in as three different channels,RGB, red, green, blue, or just one channel if it's a gray-scale image.\n",
    "\n",
    "<img src=\"images/cond-input-3.png\" width=420 height=200 />\n",
    "\n",
    "o that's this image component. Then the one-hot class information could also be fed in as additional channels where all\n",
    "the channels take on values of all zeros; so all these white blocks of the same height and width as the image take on\n",
    "values of all zeros. Whereas this black one here will take on values of ones. In contrast to that one-hot vector,\n",
    "these are typically much larger matrices where each channel is full of zeros at every position where it's not that class.\n",
    "There are many other less space consuming ways of doing this, like compressing this information in another format.\n",
    "\n",
    "###### Better approach\n",
    "Here are many other less space consuming ways of doing this, like compressing this information in another format.\n",
    "You can even create a separate neural network head to do that for you, which would be prudent if you had many different classes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Summary\n",
    "\n",
    "<img src=\"images/cond-input-4.png\" width=420 height=200 />\n",
    "\n",
    "To sum up in conditional generation, you pass the class information to both models. To the generator it's typically a\n",
    "one-hot vector concatenated with your noise vector to the discriminator when the desired output of the GANs are images,\n",
    "it's one-hot matrices representing the channels. The size of the class vector and the number of extra channels for the\n",
    "class information is just the same as the number of classes you'll be turning on."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Controllable generation\n",
    "\n",
    "Another way to control the outputs produced by gans, is after it's been trained, or more generally, controllable generation.\n",
    "While conditional generation leverages labels during training, this video will focus on controlling what features you\n",
    "want in the output examples, even after the model has been trained. You'll learn about controlling specific features,\n",
    "and how it compares with conditional generation you learned about in the previous video. Controllable generation allows\n",
    "you to control some of the features that you want in your output examples.\n",
    "\n",
    "<img src=\"images/ctr-gen-1.png\" width=420 height=200 />\n",
    "\n",
    "For instance, with a gan that performs face generation, you could control the age of the person's looks in the image or\n",
    "if they have sunglasses or the direction they're looking at in the picture, or they're perceived gender."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can do this by actually tweaking the input noise vector Z, that is fed to the generator after you train the model.\n",
    "For example, with the input noise vector Z, maybe you get this picture of a woman with red hair.\n",
    "\n",
    "<img src=\"images/ctr-gen-2.png\" width=420 height=200 />\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's say you tweak one of the features from this input noise vector here and Maybe now you get the same woman but with\n",
    "blue hair this time. Maybe its because this first element here, represents changing hair color. That would be super cool.\n",
    "You'll learn exactly how to tweak the Z in the following lecture.\n",
    "\n",
    "<img src=\"images/ctr-gen-3.png\" width=420 height=200 />"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Controllable vs Conditional Generator\n",
    "\n",
    "But first, to get a better sense of control generation, I'll make a quick comparison with conditional generation.\n",
    "I'll use these terms here because that's typically what researchers mean if you check out the papers, though it's not as\n",
    "clearly delineated\n",
    "\n",
    "<img src=\"images/ctr-gen-4.png\" width=420 height=200 />\n",
    "\n",
    "Sometimes controlable degeneration can definitely include conditional generation because you're still controlling the\n",
    "gan in some way. With controllable generation, you're able to get examples with the features that you want, like faces\n",
    "from people who look older with green hair and glasses. With conditional generation, you get examples from the class that\n",
    "you want, like a human or bird. Of course, it could also be, I want to person with sunglasses on as well. So far, they're\n",
    "a bit similar. But controllable generation typically means you want to control how much or how little of a feature you want.\n",
    "They're typically more continuous features like age. Conditional generation on the other hand, allows you to specify what\n",
    "class you want to a very different type of thing. For this, you need to have a label data set and implemented during\n",
    "training typically. You probably don't want to label every hair length value, so, controllable generation will do that\n",
    "for you and it's more about finding directions of the features you want. That can happen after training. Of course,\n",
    "controllable generation, you will sometimes also see it happening during training as well. To help nudge the model in\n",
    "a direction where it's easier to control. Finally, as you just learned, controllable generation works by tweaking that\n",
    "input noise vector Z that's fed into the generator, while with conditional generation, you have to pass additional\n",
    "information representing the class that you want appended to that noise vector."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-7a2079c2aa84>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m\"<ipython-input-1-7a2079c2aa84>\"\u001B[0;36m, line \u001B[0;32m3\u001B[0m\n\u001B[0;31m    But first, to get a better sense of control generation, I'll make a quick comparison with conditional generation. I'll use these terms here because that's typically what researchers mean if you check out the papers, though it's not as clearly delineated\u001B[0m\n\u001B[0m        ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "In summary. Controllable generation lets you control the features in the output from your gan.\n",
    "In contrast, with conditional generation, there's no need for a labeled training dataset.\n",
    "To change the output in some way with controllable generation, the input noise vector is tweaked in some other way.\n",
    "In following videos, I'll dig deeper into how exactly that works.\n",
    "\n",
    "<img src=\"images/ctr-gen-5.png\" width=420 height=200 />"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Vector Algebra in the Z-Space\n",
    "\n",
    "<img src=\"images/ctr-gen-6.png\" width=420 height=200 />\n",
    "\n",
    "As you've seen in the previous video, controllable generation is achieved by manipulating the noise vector z that's fed\n",
    "into the generator. In this video, I'll show you the intuition behind that process. I'll review how to interpolate\n",
    "between two GAN outputs first and you'll learn how to manipulate noise vectors in order to control desired features in\n",
    "your outputs.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"images/ctr-gen-7.png\" width=420 height=200 />\n",
    "\n",
    "Controllable generation and interpolation are somewhat alike. With interpolation, you get these intermediate examples\n",
    "between two generated observations. In practice, with interpolation, you can see how an image morphs into another,\n",
    "like in this GIF, where each digit from zero to nine morphs into the following one."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"images/ctr-gen-8.png\" width=420 height=200 />\n",
    "\n",
    "What happens is that you get intermediate examples between the targets by manipulating the inputs from Z-space,\n",
    "which is just the name for the vector space of the noise vectors. You'll see later that this is the same idea behind\n",
    "control bot generation. Just to be clear here, Z_1 and Z_2 are the two dimensions in this Z-space that you're looking\n",
    "at right now."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Example Latent Z Space\n",
    "\n",
    "<img src=\"images/ctr-gen-9.png\" width=420 height=200 />\n",
    "\n",
    "As an example, there's a noise vector V_1 and a noise vector V_2, where V_1 could have a Z_1 value of, let's say five\n",
    "and a Z_2 value of let's say 10. Then this is the vector 5,10 and then V_2 has a smaller value, so four and two.\n",
    "So it's the vector 4, 2. That's what Z_1 and Z_2 are, just dimensions on the Z-space and the actual vectors V_1 and\n",
    "V_2 are going to represent concrete vector values in this Z-space. V_1, when you feed it into the generator, will\n",
    "produce this image here, and V_2 when you feed it into the generator, will produce this image there."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Interpolation Latent Space Z\n",
    "\n",
    "<img src=\"images/ctr-gen-10.png\" width=420 height=200 />\n",
    "\n",
    "\n",
    "If you want to get intermediate values between these two images, you can make an interpolation between their two\n",
    "input vectors, V_1 and V_2 in the Z-space, actually. This interpolation is often a linear interpolation.\n",
    "Of course, there are other ways to interpolate between these two vectors."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"images/ctr-gen-11.png\" width=420 height=200 />\n",
    "\n",
    "Then you can take all these intermediate vectors and see what they produce from the generator.\n",
    "The generator takes this vector and produces that image, this vector, that image, and this vector, that image\n",
    "to get this gradient between these two images.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"images/ctr-gen-12.png\" width=420 height=200 />\n",
    "\n",
    " Controllable generation also uses changes in the Z-space and takes advantage of how modifications to the noise vectors\n",
    " are reflected on the output from the generator. For example, with the noise vector, you could get a picture of a woman\n",
    " with red hair and then with another noise vector, you could get a picture of the same woman but with blue hair.\n",
    " The difference between these two noise vectors is just this direction in which you have to move in Z-space to modify\n",
    " the hair color of your generated images. In controllable generation, your goal is to find these directions for\n",
    " different features you care about. For example, modifying hair color. But don't worry about finding that exact\n",
    " direction yet, I'm going to show you in the following lectures. With this known direction d, let's call this\n",
    " direction d, in your Z-space, you can now control the features on the output of your GAN, which is really exciting."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"images/ctr-gen-13.png\" width=420 height=200 />\n",
    "\n",
    "his means that if you then generate an image of a man with red hair produced by the same Generator g, with this input\n",
    "noise vector here, V_1, you can modify the hair color of this man in the image by adding that direction vector d you\n",
    "found earlier to the noise vector, creating this new noise vector here, V_1 + d, passing that into your generator and\n",
    "getting a resulting image where his hair is now blue.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"images/ctr-gen-14.png\" width=420 height=200 />\n",
    "\n",
    "To sum up, in controllable generation, you need to find the directions in the Z-space related to changes of the desired\n",
    "features on the output of your GAN. With known directions, controllable generation works by moving the noise vector in\n",
    "different directions in that Z-space. Up next, you'll learn some challenges related to controllable generation and how\n",
    "to find directions on the Z-space with known effects on the generated outputs."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-d819d301",
   "language": "python",
   "display_name": "PyCharm (MarkPy)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}